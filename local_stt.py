# local_stt.py - faster-whisper ê¸°ë°˜ ë¡œì»¬ STT (ë©”ëª¨ë¦¬ ê´€ë¦¬ í†µí•©)
import os
import tempfile
import shutil
import gc
import time
from typing import Optional, List, Tuple
from dataclasses import dataclass

import yt_dlp

# ë©”ëª¨ë¦¬ ê´€ë¦¬ì í†µí•© ì‚¬ìš© (ì¤‘ë³µ í´ë˜ìŠ¤ ì œê±°)
from memory_manager import memory_manager, whisper_manager, memory_monitor_decorator

@dataclass 
class AudioChunk:
    """ì˜¤ë””ì˜¤ ì²­í¬ ì •ë³´"""
    file_path: str
    start_time: float
    end_time: float
    duration: float

class LocalSTT:
    """faster-whisper ê¸°ë°˜ ë¡œì»¬ STT ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
    
    def __init__(self, model_size: str = "base", enable_chunking: bool = True, chunk_duration: int = 600):
        self.model_size = model_size
        self.enable_chunking = enable_chunking
        self.chunk_duration = chunk_duration  # ì´ˆ ë‹¨ìœ„
        self._temp_dir = None
        
        print(f"ğŸ¤ LocalSTT ì´ˆê¸°í™”: ëª¨ë¸={model_size}, ì²­í‚¹={enable_chunking}")
    
    def _get_model(self):
        """í†µí•©ëœ Whisper ëª¨ë¸ ë§¤ë‹ˆì € ì‚¬ìš©"""
        return whisper_manager.get_model(self.model_size)
    
    def _setup_temp_dir(self):
        """ì„ì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •"""
        if self._temp_dir is None:
            self._temp_dir = tempfile.mkdtemp(prefix="whisper_stt_")
            print(f"ğŸ“ ì„ì‹œ ë””ë ‰í† ë¦¬: {self._temp_dir}")
    
    @memory_monitor_decorator
    def transcribe(self, video_url: str) -> 'STTResult':
        """ë©”ì¸ STT ì²˜ë¦¬ í•¨ìˆ˜ (ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ í¬í•¨)"""
        from safe_stt_engine import STTResult, STTProvider
        
        start_time = time.time()
        
        try:
            self._setup_temp_dir()
            
            # ë©”ëª¨ë¦¬ ì••ë°• ìƒí™© ì²´í¬
            if memory_manager.check_memory_pressure(threshold_mb=2500):
                print("âš ï¸ ë©”ëª¨ë¦¬ ì••ë°• ìƒí™© - ì •ë¦¬ í›„ ì§„í–‰")
                memory_manager.force_cleanup(aggressive=True)
            
            # 1. ì˜¤ë””ì˜¤ ì¶”ì¶œ
            print("ğŸµ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
            audio_file = self._extract_audio(video_url)
            if not audio_file:
                return STTResult(
                    success=False,
                    text="",
                    provider=STTProvider.LOCAL,
                    duration_seconds=time.time() - start_time,
                    error_message="ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨"
                )
            
            # 2. ì˜¤ë””ì˜¤ ì •ë³´ í™•ì¸
            duration = self._get_audio_duration(audio_file)
            file_size_mb = os.path.getsize(audio_file) / 1024 / 1024
            
            print(f"ğŸµ ì˜¤ë””ì˜¤ ì •ë³´: {duration:.1f}ì´ˆ, {file_size_mb:.1f}MB")
            
            # ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ì‘ì€ ëª¨ë¸ë¡œ ë³€ê²½
            current_memory = memory_manager.get_memory_usage()["rss"]
            if current_memory > 2000 and self.model_size != "tiny":
                print(f"âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡± ({current_memory:.0f}MB) - tiny ëª¨ë¸ë¡œ ë³€ê²½")
                original_size = self.model_size
                self.model_size = "tiny"
                whisper_manager.clear_model()  # ê¸°ì¡´ ëª¨ë¸ í•´ì œ
            
            # 3. ì²­í‚¹ ì—¬ë¶€ ê²°ì • ë° ì²˜ë¦¬
            if self.enable_chunking and duration > self.chunk_duration:
                print(f"ğŸ“Š ì²­í‚¹ ì²˜ë¦¬ ëª¨ë“œ: {duration:.1f}ì´ˆ â†’ {self.chunk_duration}ì´ˆ ë‹¨ìœ„")
                result = self._transcribe_chunks(audio_file, duration)
            else:
                print("ğŸ¤ ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ")
                result = self._transcribe_single(audio_file)
            
            # ì²˜ë¦¬ ì‹œê°„ ì„¤ì •
            result.duration_seconds = time.time() - start_time
            return result
            
        except Exception as e:
            print(f"âŒ ë¡œì»¬ STT ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return STTResult(
                success=False,
                text="",
                provider=STTProvider.LOCAL,
                duration_seconds=time.time() - start_time,
                error_message=str(e)
            )
        finally:
            self._cleanup_temp_files()
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
    
    def _extract_audio(self, video_url: str) -> Optional[str]:
        """yt-dlpë¡œ ì˜¤ë””ì˜¤ ì¶”ì¶œ (ìµœì í™”)"""
        try:
            audio_output = os.path.join(self._temp_dir, "audio.wav")
            
            # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ ìµœì í™”ëœ ì„¤ì •
            ydl_opts = {
                'format': 'bestaudio[filesize<100M]/bestaudio/best[filesize<100M]',  # 100MB ì œí•œ
                'outtmpl': audio_output.replace('.wav', '.%(ext)s'),
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'wav',
                    'preferredquality': '16',  # 16kHzë¡œ í’ˆì§ˆ ë‚®ì¶¤
                }],
                'postprocessor_args': [
                    '-ac', '1',          # ëª¨ë…¸ ì±„ë„
                    '-ar', '16000',      # 16kHz ìƒ˜í”Œë§
                    '-acodec', 'pcm_s16le',  # 16bit PCM
                    '-t', '7200',        # ìµœëŒ€ 2ì‹œê°„ ì œí•œ
                ],
                'quiet': True,
                'no_warnings': True,
                'extractaudio': True,
                'audioformat': 'wav',
            }
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([video_url])
            
            # ì¶”ì¶œëœ íŒŒì¼ ì°¾ê¸°
            for file in os.listdir(self._temp_dir):
                if file.startswith('audio') and file.endswith('.wav'):
                    result_path = os.path.join(self._temp_dir, file)
                    
                    # íŒŒì¼ í¬ê¸° ì²´í¬
                    size_mb = os.path.getsize(result_path) / 1024 / 1024
                    if size_mb > 500:  # 500MB ì´ˆê³¼ì‹œ ê²½ê³ 
                        print(f"âš ï¸ ëŒ€ìš©ëŸ‰ ì˜¤ë””ì˜¤ íŒŒì¼: {size_mb:.1f}MB")
                    
                    print(f"âœ… ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ: {file} ({size_mb:.1f}MB)")
                    return result_path
            
            print("âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return None
            
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _get_audio_duration(self, audio_file: str) -> float:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ê¸¸ì´ í™•ì¸ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)"""
        try:
            # ë°©ë²• 1: wave ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
            import wave
            with wave.open(audio_file, 'r') as wav_file:
                frames = wav_file.getnframes()
                rate = wav_file.getframerate()
                duration = frames / float(rate)
                return duration
        except Exception:
            pass
        
        try:
            # ë°©ë²• 2: ffmpeg-python ì‚¬ìš©
            import ffmpeg
            probe = ffmpeg.probe(audio_file)
            duration = float(probe['streams'][0]['duration'])
            return duration
        except Exception:
            pass
        
        # ë°©ë²• 3: íŒŒì¼ í¬ê¸°ë¡œ ì¶”ì • (16kHz, 16bit, mono ê¸°ì¤€)
        try:
            file_size = os.path.getsize(audio_file)
            estimated_duration = file_size / (16000 * 2)  # 16kHz * 2bytes
            print(f"âš ï¸ ê¸¸ì´ ì¶”ì •: {estimated_duration:.1f}ì´ˆ (íŒŒì¼ í¬ê¸° ê¸°ì¤€)")
            return estimated_duration
        except Exception:
            return 1800.0  # ê¸°ë³¸ê°’ 30ë¶„
    
    def _create_audio_chunks(self, audio_file: str, duration: float) -> List[AudioChunk]:
        """ì˜¤ë””ì˜¤ë¥¼ ì²­í¬ë¡œ ë¶„í•  (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )"""
        chunks = []
        
        try:
            import ffmpeg
            
            chunk_count = int(duration / self.chunk_duration) + 1
            print(f"ğŸ“Š {chunk_count}ê°œ ì²­í¬ë¡œ ë¶„í•  ì²˜ë¦¬ ì˜ˆì •")
            
            # ë„ˆë¬´ ë§ì€ ì²­í¬ëŠ” ë©”ëª¨ë¦¬ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥
            if chunk_count > 20:
                print(f"âš ï¸ ì²­í¬ ìˆ˜ ì œí•œ: {chunk_count} â†’ 20ê°œ")
                chunk_count = 20
                self.chunk_duration = int(duration / 20)
            
            for i in range(chunk_count):
                start_time = i * self.chunk_duration
                end_time = min(start_time + self.chunk_duration, duration)
                
                if start_time >= duration:
                    break
                
                chunk_file = os.path.join(self._temp_dir, f"chunk_{i:03d}.wav")
                
                try:
                    # ffmpegë¡œ ì²­í¬ ì¶”ì¶œ
                    (
                        ffmpeg
                        .input(audio_file, ss=start_time, t=(end_time - start_time))
                        .output(
                            chunk_file, 
                            acodec='pcm_s16le', 
                            ac=1, 
                            ar=16000,
                            loglevel='quiet'
                        )
                        .overwrite_output()
                        .run(capture_stdout=True, capture_stderr=True)
                    )
                    
                    if os.path.exists(chunk_file) and os.path.getsize(chunk_file) > 1000:
                        chunks.append(AudioChunk(
                            file_path=chunk_file,
                            start_time=start_time,
                            end_time=end_time,
                            duration=end_time - start_time
                        ))
                    else:
                        print(f"âš ï¸ ì²­í¬ {i} ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ")
                        
                except Exception as e:
                    print(f"âš ï¸ ì²­í¬ {i} ë¶„í•  ì‹¤íŒ¨: {e}")
                    continue
            
            print(f"âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
            return chunks
            
        except ImportError:
            print("âš ï¸ ffmpeg-python ë¯¸ì„¤ì¹˜, ë‹¨ì¼ íŒŒì¼ë¡œ ì²˜ë¦¬")
            return [AudioChunk(
                file_path=audio_file,
                start_time=0,
                end_time=duration,
                duration=duration
            )]
        except Exception as e:
            print(f"âš ï¸ ì²­í¬ ë¶„í•  ì‹¤íŒ¨: {e}, ë‹¨ì¼ íŒŒì¼ë¡œ ì²˜ë¦¬")
            return [AudioChunk(
                file_path=audio_file,
                start_time=0,
                end_time=duration,
                duration=duration
            )]
    
    def _transcribe_chunks(self, audio_file: str, duration: float) -> 'STTResult':
        """ì²­í¬ ë‹¨ìœ„ë¡œ STT ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
        from safe_stt_engine import STTResult, STTProvider
        
        chunks = self._create_audio_chunks(audio_file, duration)
        if not chunks:
            return STTResult(
                success=False,
                text="",
                provider=STTProvider.LOCAL,
                duration_seconds=0,
                error_message="ì²­í¬ ìƒì„± ì‹¤íŒ¨"
            )
        
        model = self._get_model()
        if not model:
            return STTResult(
                success=False,
                text="",
                provider=STTProvider.LOCAL,
                duration_seconds=0,
                error_message="Whisper ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"
            )
        
        all_texts = []
        processed_chunks = 0
        failed_chunks = 0
        
        for i, chunk in enumerate(chunks):
            try:
                print(f"ğŸ¤ ì²­í¬ {i+1}/{len(chunks)} ì²˜ë¦¬ ì¤‘... ({chunk.start_time:.1f}s-{chunk.end_time:.1f}s)")
                
                # ë©”ëª¨ë¦¬ ì²´í¬ (ë§¤ 3ì²­í¬ë§ˆë‹¤)
                if i % 3 == 0:
                    current_memory = memory_manager.get_memory_usage()["rss"]
                    if current_memory > 3000:  # 3GB ì´ˆê³¼
                        print(f"âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì²­í¬ ì²˜ë¦¬ ì¤‘ë‹¨ ({i+1}/{len(chunks)}) - {current_memory:.0f}MB")
                        break
                
                # STT ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì •)
                segments, info = model.transcribe(
                    chunk.file_path,
                    language="ko",
                    condition_on_previous_text=False,  # ë©”ëª¨ë¦¬ ì ˆì•½
                    temperature=0.0,
                    compression_ratio_threshold=2.4,
                    no_speech_threshold=0.6,
                    beam_size=1,  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ beam size ê°ì†Œ
                    best_of=1     # ë©”ëª¨ë¦¬ ì ˆì•½
                )
                
                # ê²°ê³¼ ìˆ˜ì§‘
                chunk_texts = []
                for segment in segments:
                    text = segment.text.strip()
                    if text and len(text) > 1:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
                        chunk_texts.append(text)
                
                chunk_text = " ".join(chunk_texts).strip()
                if chunk_text:
                    all_texts.append(chunk_text)
                    processed_chunks += 1
                else:
                    failed_chunks += 1
                
                # ì²­í¬ íŒŒì¼ ì¦‰ì‹œ ì‚­ì œ (ë©”ëª¨ë¦¬ ì ˆì•½)
                if chunk.file_path != audio_file:  # ì›ë³¸ íŒŒì¼ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                    try:
                        os.remove(chunk.file_path)
                    except:
                        pass
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë§¤ ì²­í¬ë§ˆë‹¤)
                del segments, info, chunk_texts, chunk_text
                gc.collect()
                
                # ì§„í–‰ë¥  ì¶œë ¥
                if (i + 1) % 5 == 0 or i == len(chunks) - 1:
                    print(f"ğŸ“Š ì§„í–‰ë¥ : {i+1}/{len(chunks)} ì²­í¬ ì™„ë£Œ (ì„±ê³µ: {processed_chunks}, ì‹¤íŒ¨: {failed_chunks})")
                
            except Exception as e:
                print(f"âŒ ì²­í¬ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                failed_chunks += 1
                continue
        
        # ìµœì¢… ê²°ê³¼ ì¡°í•©
        final_text = " ".join(all_texts).strip()
        success = len(final_text) > 50 and processed_chunks > 0
        confidence = processed_chunks / len(chunks) if chunks else 0
        
        print(f"âœ… ì²­í‚¹ STT ì™„ë£Œ: {processed_chunks}/{len(chunks)} ì²­í¬ ì„±ê³µ, {len(final_text)}ì ìƒì„±")
        
        if failed_chunks > processed_chunks:
            print(f"âš ï¸ ì‹¤íŒ¨ ì²­í¬ê°€ ë§ìŒ: ì„±ê³µ {processed_chunks} vs ì‹¤íŒ¨ {failed_chunks}")
        
        return STTResult(
            success=success,
            text=final_text,
            provider=STTProvider.LOCAL,
            duration_seconds=0,  # ë‚˜ì¤‘ì— ì„¤ì •ë¨
            chunks_processed=processed_chunks,
            confidence=confidence
        )
    
    def _transcribe_single(self, audio_file: str) -> 'STTResult':
        """ë‹¨ì¼ íŒŒì¼ STT ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
        from safe_stt_engine import STTResult, STTProvider
        
        try:
            model = self._get_model()
            if not model:
                return STTResult(
                    success=False,
                    text="",
                    provider=STTProvider.LOCAL,
                    duration_seconds=0,
                    error_message="Whisper ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"
                )
            
            print("ğŸ¤ ë‹¨ì¼ íŒŒì¼ STT ì²˜ë¦¬ ì¤‘...")
            
            # íŒŒì¼ í¬ê¸° ì²´í¬
            file_size_mb = os.path.getsize(audio_file) / 1024 / 1024
            if file_size_mb > 200:  # 200MB ì´ˆê³¼ì‹œ ê²½ê³ 
                print(f"âš ï¸ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬: {file_size_mb:.1f}MB")
            
            # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì •ìœ¼ë¡œ STT ì²˜ë¦¬
            segments, info = model.transcribe(
                audio_file,
                language="ko",
                condition_on_previous_text=False,
                temperature=0.0,
                compression_ratio_threshold=2.4,
                no_speech_threshold=0.6,
                beam_size=1,  # ë©”ëª¨ë¦¬ ì ˆì•½
                best_of=1     # ë©”ëª¨ë¦¬ ì ˆì•½
            )
            
            # ê²°ê³¼ ìˆ˜ì§‘ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
            all_texts = []
            segment_count = 0
            
            for segment in segments:
                text = segment.text.strip()
                if text and len(text) > 1:
                    all_texts.append(text)
                    segment_count += 1
                
                # ë„ˆë¬´ ë§ì€ ì„¸ê·¸ë¨¼íŠ¸ì‹œ ì¤‘ê°„ ì •ë¦¬
                if segment_count % 100 == 0:
                    gc.collect()
            
            final_text = " ".join(all_texts).strip()
            success = len(final_text) > 20
            
            print(f"âœ… ë‹¨ì¼ STT ì™„ë£Œ: {segment_count}ê°œ ì„¸ê·¸ë¨¼íŠ¸, {len(final_text)}ì")
            
            return STTResult(
                success=success,
                text=final_text,
                provider=STTProvider.LOCAL,
                duration_seconds=0,
                chunks_processed=1,
                confidence=1.0 if success else 0.0
            )
            
        except Exception as e:
            print(f"âŒ ë‹¨ì¼ STT ì‹¤íŒ¨: {e}")
            return STTResult(
                success=False,
                text="",
                provider=STTProvider.LOCAL,
                duration_seconds=0,
                error_message=str(e)
            )
    
    def _cleanup_temp_files(self):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ì•ˆì „í•œ ì‚­ì œ)"""
        if self._temp_dir and os.path.exists(self._temp_dir):
            try:
                # íŒŒì¼ ê°œìˆ˜ í™•ì¸
                file_count = len(os.listdir(self._temp_dir))
                total_size = sum(
                    os.path.getsize(os.path.join(self._temp_dir, f)) 
                    for f in os.listdir(self._temp_dir)
                ) / 1024 / 1024
                
                shutil.rmtree(self._temp_dir, ignore_errors=True)
                print(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: {file_count}ê°œ íŒŒì¼, {total_size:.1f}MB")
            except Exception as e:
                print(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            finally:
                self._temp_dir = None
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (í†µí•©ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì‚¬ìš©)"""
        print("ğŸ—‘ï¸ LocalSTT ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        self._cleanup_temp_files()
        
        # í†µí•© ëª¨ë¸ ê´€ë¦¬ìë¥¼ í†µí•œ ì •ë¦¬ (ì¤‘ë³µ ì œê±°)
        # whisper_manager.clear_model()  # í•„ìš”ì‹œì—ë§Œ í˜¸ì¶œ
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        memory_manager.force_cleanup(aggressive=True)
        
        print("âœ… LocalSTT ì •ë¦¬ ì™„ë£Œ")
    
    def get_model_info(self) -> dict:
        """í˜„ì¬ ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        model_info = whisper_manager.get_model_info()
        if model_info:
            return model_info
        else:
            return {
                "size": self.model_size,
                "loaded": False,
                "device": "cpu",
                "compute_type": "int8"
            }
    
    def is_model_loaded(self) -> bool:
        """ëª¨ë¸ ë¡œë”© ìƒíƒœ í™•ì¸"""
        return whisper_manager.is_loaded()

# í¸ì˜ í•¨ìˆ˜ë“¤
def transcribe_video_local(video_url: str, model_size: str = "base", enable_chunking: bool = True) -> dict:
    """
    ë‹¨ì¼ í•¨ìˆ˜ë¡œ ë¡œì»¬ STT ì²˜ë¦¬
    
    Args:
        video_url: YouTube URL
        model_size: Whisper ëª¨ë¸ í¬ê¸° (tiny, base, small)
        enable_chunking: ì²­í‚¹ ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼
    """
    local_stt = LocalSTT(model_size=model_size, enable_chunking=enable_chunking)
    
    try:
        result = local_stt.transcribe(video_url)
        
        return {
            "success": result.success,
            "text": result.text,
            "duration": result.duration_seconds,
            "chunks_processed": result.chunks_processed,
            "confidence": result.confidence,
            "error": result.error_message,
            "model_info": local_stt.get_model_info()
        }
    finally:
        local_stt.cleanup()

def estimate_processing_time(video_duration_minutes: float, model_size: str = "base") -> dict:
    """
    ë¡œì»¬ STT ì²˜ë¦¬ ì‹œê°„ ì¶”ì •
    
    Args:
        video_duration_minutes: ì˜ìƒ ê¸¸ì´ (ë¶„)
        model_size: ëª¨ë¸ í¬ê¸°
    
    Returns:
        dict: ì‹œê°„ ì¶”ì • ì •ë³´
    """
    # ëª¨ë¸ë³„ ì²˜ë¦¬ ì†ë„ (ì‹¤ì œ ì‹œê°„ ëŒ€ë¹„ ë°°ìˆ˜)
    speed_multipliers = {
        "tiny": 0.1,   # 10% ì‹œê°„ (ë§¤ìš° ë¹ ë¦„)
        "base": 0.15,  # 15% ì‹œê°„ (ë³´í†µ)
        "small": 0.25, # 25% ì‹œê°„ (ëŠë¦¼)
        "medium": 0.4, # 40% ì‹œê°„ (ë§¤ìš° ëŠë¦¼)
        "large": 0.6   # 60% ì‹œê°„ (ê°€ì¥ ëŠë¦¼)
    }
    
    multiplier = speed_multipliers.get(model_size, 0.15)
    estimated_minutes = video_duration_minutes * multiplier
    
    return {
        "video_duration": video_duration_minutes,
        "model_size": model_size,
        "estimated_processing_minutes": estimated_minutes,
        "estimated_processing_time": f"{int(estimated_minutes)}ë¶„ {int((estimated_minutes % 1) * 60)}ì´ˆ",
        "speed_multiplier": multiplier,
        "memory_usage_mb": {
            "tiny": 500,
            "base": 1000,
            "small": 2000,
            "medium": 4000,
            "large": 8000
        }.get(model_size, 1000)
    }

# ì‹œìŠ¤í…œ ì²´í¬ í•¨ìˆ˜
def check_local_stt_requirements() -> dict:
    """ë¡œì»¬ STT ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ì²´í¬"""
    requirements = {
        "faster_whisper": False,
        "yt_dlp": False,
        "ffmpeg_python": False,
        "torch": False,
        "system_memory_gb": 0,
        "available_models": [],
        "recommended_model": "base"
    }
    
    try:
        import faster_whisper
        requirements["faster_whisper"] = True
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì²´í¬
        try:
            test_model = faster_whisper.WhisperModel("tiny", device="cpu")
            requirements["available_models"].append("tiny")
            del test_model
            gc.collect()
        except:
            pass
            
    except ImportError:
        pass
    
    try:
        import yt_dlp
        requirements["yt_dlp"] = True
    except ImportError:
        pass
    
    try:
        import ffmpeg
        requirements["ffmpeg_python"] = True
    except ImportError:
        pass
    
    try:
        import torch
        requirements["torch"] = True
    except ImportError:
        pass
    
    # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì²´í¬
    try:
        import psutil
        memory_gb = psutil.virtual_memory().total / (1024**3)
        requirements["system_memory_gb"] = round(memory_gb, 1)
        
        # ë©”ëª¨ë¦¬ ê¸°ë°˜ ê¶Œì¥ ëª¨ë¸
        if memory_gb < 4:
            requirements["recommended_model"] = "tiny"
        elif memory_gb < 8:
            requirements["recommended_model"] = "base"
        else:
            requirements["recommended_model"] = "small"
            
    except ImportError:
        pass
    
    # ì „ì²´ ì¤€ë¹„ ìƒíƒœ
    requirements["ready"] = all([
        requirements["faster_whisper"],
        requirements["yt_dlp"],
        requirements["torch"]
    ])
    
    return requirements